---
title: "STAT 6620 HW#6"
author: "Lanqin Zhao,   NetID: ae8275"
output: html_notebook
---

### Identifying loan default using Random Forest

## Step 1 - collecting data ----
We will utilize credit.csv file. It includes 1000 examples and 17  variables. The response variable is default.

## Step 2: Exploring and preparing the data ----
Explore the data to see whether we can use the data to identify loan default and prepare the data for modeling.

# Import data
```{r}
credit <- read.csv("http://www.sci.csueastbay.edu/~esuess/classes/Statistics_6620/Presentations/ml7/credit.csv")


# examine the credit data
str(credit)

```

# Check if there are any missing values

```{r}
# number of missing values in each column

sapply(credit,function(x) sum(is.na(x)))

# number of unique values in each column

sapply(credit, function(x) length(unique(x)))

```

# Prepare trainning and test data sets
```{r}
indx = sample(1:nrow(credit), as.integer(0.9*nrow(credit)))

credit_train = credit[indx,]
credit_test = credit[-indx,-17]

credit_train_labels = credit[indx,17]
credit_test_labels = credit[-indx,17]   

```

## Step 3: Training a model on the data ----

```{r}
# fit the logistic regression model, with all predictor variables

library(randomForest)
set.seed(300)
rf <- randomForest(default  ~., data=credit_train)
rf



```


## Step 4: Evaluating model performance ----
Use confusion matrix, accuracy to evaluate model performance. The accuracy is 78%, which is  good. 

```{r}
# predictions on test data
fitted.results <- predict(rf,newdata=credit_test,type='response')


# Confusion Matrix

CrossTable(credit_test_labels, fitted.results ,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

# compute accuracy
misClasificError <- mean(fitted.results != credit_test_labels)
print(paste('Accuracy',1-misClasificError))

```

## Step 5: Improving model performance ----

Build and compare an auto-tuned random forest. With a kappa of about 0.361, the random forest model with mtry = 16 was the winner. Its accuracy is 0.75.

```{r}
library(caret)
ctrl <- trainControl(method = "repeatedcv",number = 10, repeats = 10)
grid_rf <- expand.grid(.mtry = c(2, 4, 8, 16))
set.seed(300)
m_rf <- train(default ~ ., data = credit_train, method = "rf",metric = "Kappa", trControl =ctrl, tuneGrid = grid_rf) 
m_rf

```



```{r}
# predictions on test data
fitted.results <- predict(m_rf,newdata=credit_test)

# Confusion Matrix

CrossTable(credit_test_labels, fitted.results ,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

# compute accuracy
misClasificError <- mean(fitted.results != credit_test_labels)
print(paste('Accuracy',1-misClasificError))
```





