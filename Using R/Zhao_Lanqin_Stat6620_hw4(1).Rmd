---
title: "STAT 6620 HW#4"
author: "Lanqin Zhao,   NetID: ae8275"
output: html_notebook
---

### Identifying risky bank loans using C5.0 decision trees

## Step 1 - collecting data ----
We will utilize the credit dataset from the UCI Machine Learning Repository at http://archive.ics.uci.edu/ml. This data was donated by Hans Hofmann of the University of Hamburg. The dataset contains information on loans obtained from a credit agency in Germany.
The credit dataset includes 1,000 examples on loans, plus a set of numeric and nominal features indicating the characteristics of the loan and the loan applicant. A class variable indicates whether the loan went into default.

## Step 2: Exploring and preparing the data ----
Explore the data to see whether we can use the data to classify and prepare the data for modeling.
# Explore data
Import data

```{r}
#Import the CSV file.
credit <- read.csv("credit.csv")
str(credit)

```
Let's take a look at outputs for a couple of features that seem likely to predict a default.

```{r}
# look at two characteristics of the applicant
table(credit$checking_balance)
table(credit$savings_balance)
```
```{r}
# look at two characteristics of the loan
summary(credit$months_loan_duration)
summary(credit$amount)
```
look at the class variable. A total of 30 percent of the loans in this dataset 
went into default:

```{r}
# look at the class variable
table(credit$default)
```
# Data preparation - creating training and test datasets
Create training and test data to build models.

```{r}
# create a random sample for training and test data
set.seed(123)
train_sample <- sample(1000, 900)

str(train_sample)
```
split the data frames to training and test data

```{r}
# split the data frames 
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
```
check the proportion of class variable in training and test datasets. They are close, this appears to be a fairly even split.
```{r}
# check the proportion of class variable
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
```

## Step 3: Training a model on the data ----
This time, we train a simplest decision tree model on the data. 
```{r}
# build the simplest decision tree

library(C50)
credit_model <- C5.0(credit_train[-17], credit_train$default)
```

```{r}
# display simple facts about the tree
credit_model
```
```{r}
# display detailed information about the tree
summary(credit_model)
```
## Step 4: Evaluating model performance ----
Create the cross tabulation of predicted vs. actual to evaluating model performance. 
From the below table, the accuracy is 73%.  More importantly, the model only correctly predicted 14 of the 33 actual loan defaults in the test data, or 42 percent. Unfortunately, this type of error is a potentially very costly mistake, as the bank loses money on each default. We need to improve the result with a bit more effort.

```{r}
# create a factor vector of predictions on test data
credit_pred <- predict(credit_model, credit_test)

# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(credit_test$default, credit_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```

## Step 5: Improving model performance ----
We will attempt two ways to improve model performance. First, we will employ boosting. This is a process in which many decision trees are built and the trees vote on the best class for each example. Second, we will assign a penalty to different types of errors, in order to discourage a tree from making more costly mistakes. The penalties are designated in a cost matrix, which specifies how much costlier each error is, relative to any other prediction.

# Boosting the accuracy of decision trees
Boosted decision tree with 10 trials, a number that has become the de facto standard, as research suggests that this reduces error rates on test data by about 25 percent. From the below confusion matrix, the accuracy is 82%, which is much higher than previous 73% . we reduced the total error rate from 27 percent prior to boosting down to 18 percent in the boosted model, which is in fact larger than the 25 percent reduction we expected. On the other hand, the model is still not doing well at predicting defaults, predicting only 20/33 = 61% correctly.

```{r}
# boosted decision tree with 10 trials
credit_boost10 <- C5.0(credit_train[-17], credit_train$default,
                       trials = 10)
credit_boost10
summary(credit_boost10)

credit_boost_pred10 <- predict(credit_boost10, credit_test)
CrossTable(credit_test$default, credit_boost_pred10,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

```

# assign a penalty to different types of errors
Giving a loan out to an applicant who is likely to default can be an expensive mistake. One solution to reduce the number of false negatives may be to reject a larger number of borderline applicants, under the assumption that the interest the bank would earn from a risky loan is far outweighed by the massive loss it would incur if the money is not paid back at all. The C5.0 algorithm allows us to assign a penalty to different types of errors.
From the confusion matrix below, the accuracy is 63%, which is much lower than 82% the boosted model produced. This model makes more mistakes overall: 37 percent error here versus 18 percent in the boosted case. However, the types of mistakes are very different. Where the previous models classified 61 percent of actual defaults correctly, in this model, 79 percent of the actual defaults were predicted to be defaults. This trade resulting in a reduction of false negatives at the expense of increasing false positives may be acceptable if our cost estimates were accurate.
```{r}
# create dimensions for a cost matrix
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
```
```{r}
# build the matrix
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2, dimnames = matrix_dimensions)
error_cost
```
```{r}
# apply the cost matrix to the tree
credit_cost <- C5.0(credit_train[-17], credit_train$default,
                    costs = error_cost)
credit_cost_pred <- predict(credit_cost, credit_test)

CrossTable(credit_test$default, credit_cost_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```








